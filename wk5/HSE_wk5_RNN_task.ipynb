{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSE-wk5-RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7i2oVsvLfuvn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "w5COS5xtgppq",
        "colab_type": "code",
        "outputId": "bb4a4fbf-b3b8-4117-bc6c-481f5f998e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2018-12-19 04:50:32--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-19 04:50:32 (51.4 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "LihJfGPOfuvo",
        "colab_type": "code",
        "outputId": "a0bf155a-d322-412f-87de-40c6406bed8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZF3HOMvpfuvt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "KJgR7Byjfuvt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "kd8Sd6IIfuvy",
        "colab_type": "code",
        "outputId": "8c04d484-8944-4b58-d3e6-1f30b876c199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "5m6-ZMmIfuv2",
        "colab_type": "code",
        "outputId": "37fffb88-9e25-4dbf-b6e0-9c2200ef142e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAG61JREFUeJzt3X2cXVV97/HPmEAxIZoJHE1M0QjU\nL1WstzcipZASeRBBkSog90VASVCpKBWp1eADCGpBuZR6georQhIErWAwkhRLuAkgARFirFaq/ni6\nohIkg4SYkJjHuX/sNXgczpk5cx7nLL7v12te2Xvtvdf67T2T31ln7X3O6unv78fMzPL1gk4HYGZm\nreVEb2aWOSd6M7PMOdGbmWXOid7MLHNO9GZmmXOiNyRNl7RC0s8lPSDpHkmHdDquZpE0TdL2FtX9\nJ5LeVbbeL+lP66hne4rz7ZLmD7OvJP1NlW1vkLQsLS+U9Mk6Ynlv2fLPJb10pHXY6DK20wFYZ0nq\nAZYC742Im1PZO4CbJO0VEZs6GuDo95fAu4CvNqOyiFgMLB5mt7dT/N+9s8Lx9wFH1du+pMnAR4Gv\npPr2q7cuGz2c6G1PYArw/YGCiPiWpPsGkryk9wHnALsB9wBzImKzpH2AfwP2SOV7At8A7gAeioix\n6fhpA+vpheVTwKxU37eBcyJih6Q7gCXAO4BXUiSykyOiX9KbgUuBXYAHgHdFxFOSDgb+BegFnkz7\nP1LtZBto/zTgYuAJ4DJgATCZIim/SNLKiJiRmjlG0hnpul4aEZdWiONo4HJgGzC/rPw04JSIOELS\noamt3YAe4Dzg98C5wFZJvRQv0v8E/DrV9RXgqojYN1U5VdJ3gWnAD1Pdz0jqB/aKiF+ndvuBvdI5\n/6mknwN/AWwZ2E/S3wN/RzESEMB7IqJP0kLgUeCvgVel389x7iSMHh66sSeBVcDtkk6X9EqAsgQw\nA/gMcFhETAPWp3WAzwMrImIf4Erg8BraOwV4J/AGYJ/08/6y7ccCR1IkjMOAv5Y0HvgacFJEvAp4\nCPiMpAkUie7jKbF9EbihBe1PAv4VOIKiB39UukZPUCTde8qSPMC0iJgOvA34rKRdygOQNAa4Gjgz\nIv4c2AmMqRDr/wY+HBGvTnW9PSKWUry4fDEi/iHt95fAlyNiVoU6jgZOAPYGJgHvGfryMAf4ZUTs\nFxFby2L+K+AfgZmpl/9L4KKy404ETqK4niWKdx02SjjRP89FRD9FYlsMfAh4RNJ/p+EbKBLf9RGx\nJq1/maLHC3AIcH2q5x7gwRqaPBaYHxHrI2I7cFVZfQCLImJzRDxD0TN8OXAw8KuIuD/t81Hgw8AM\n4NcR8X9TDP8G7Cvp5U1u/0DggYi4PyJ2Al8a5hyvS//+J0VvfM9B2/8M2C0ibk3rC6vUsxZ4l6T9\nIuLBiDi5yn6bI+K2Ktu+ExF9EbED+BZw0DCxV/MWimuzNq1fBbypbPvNEfFUuqY/obhuNkp46MaI\niPXA+cD56cbbacA3JL0OmAi8XdLAf+oXALum5UnA02VVrWV4E4GPpOEgKP4G+8q2ry9b3kHR092z\nvJ2BnqakicA+aZhhwBaKHuUvm9h+L/BUWflj1U4u+V2Kc4ckeG5vfdLAPsm6KvXMAT4JLJe0GTg3\nIhZV2O+pCmUDBp9b7xD7DqUErClbXwe8ZFDdAwaum40STvTPc+kJkWkRcRc8OxzxeUnvBF5D8Z/7\nmoj4SIXDnwZeXLZeSv/uAF4gqSe9YyhPLmuAJRFxxQjCfJKyXrGkcRTJcg3ws4h4/Qjqqqf93wG7\nl61PGcGxlawDXlS2Xqq0U/pdnAWclV5ovyXplhG2NalsufwF69nhojTWP5wnKO7FDNgjlVkX8NCN\n7QV8W9L0gQJJB1C89V5FujkpqZS2HSfpY2nXe0jDHmks/1Wp/EmKZP/atP7s44fATcCpKVkj6QxJ\n7x4mxruAySkuKG6mngfcC0yRdGCqa29J16YbrtXU0/5q4C8k7SvpBfzxOPc2ipuxQ7U52EPAdkkz\n0/ps4I++RlbSLpLukDTworI6tbUz/TuxxraOltSb7gu8HViZyh8HXpeW56R6B85nd0mDO4E3U/wd\nDCT7M1KZdQEn+ue5NLb+PuBLkkLSQxRPepwUEY9GxA8pnuq4Q9LPKJ6+uSkdPhd4m6SHgfeSkkhE\nbKYYCrpF0g+AH5U1+W2KG6g/TEMubwOWDRPjJuB44DpJD1A8DfLx1M4JwOUptsXAN9O7iGrqaf9x\n4OPA7RQvLivLNt8FvAxYk5LpsCJiG8U1n5/i3glsrLDPVcAKST8Fvgucla7FUuDvJFUaxhlsKXAj\n8DBFD3xBKv8Exe/8R8Az/GEo6b8oev2/Kb/XkR7bvBhYma7bxFSHdYEefx+9NYuk5cB1EbGw07E0\nW9kwFJJeA9wVEfWOd5u1lXv0ZsNIwxiPDQwRUTxGeE8HQzIbESd6s2GkRwY/AFyTho4OBf6+s1GZ\n1c5DN2ZmmXOP3swsc6PyOfq+vg2j8m1Gb+841q3rzq/vcOyd4djbr1vjhsZjL5UmVHzM1z36ERg7\ntns/7OfYO8Oxt1+3xg2ti92J3swsc070ZmaZc6I3M8ucE72ZWeac6M3MMudEb2aWOSd6M7PMOdGb\nmWXOid7MLHOj8isQbHSZc3G1eacrmz/3sBZFYmb1cI/ezCxzNfXoJX0BmJH2v4hiLtFrKSYXfhw4\nNSK2SJoFnE0xNdq8iLha0i7AQuAVFPOIzo6IR5p9ImZmVtmwPXpJbwT2j4iDgDcD/wJcCFwZETMo\nJjqeI2k8xYTNRwAzgQ9LmgScDDwdEYcAn6N4oTAzszapZejmTuDEtPw0MJ4ikS9JZUspkvuBwKqI\nWJ8mbb4bOBg4nGLSZoDlqczMzNpk2KGbiNhBMUs8wOnAd4CjImJLKlsLTAEmA31lhz6nPCJ2SuqX\ntGtEbK3WZm/vuFH7VaOl0oROh1C3dsXeinZ83TujW2Pv1rihNbHX/NSNpOMoEv2bgAfLNlX8ovs6\nyp81WicNKJUm0Ne3odNh1KWdsTe7HV/3zujW2Ls1bmg89movEjU9dSPpKOATwNERsR7YKOmFafNU\nYE36mVx22HPK043ZnqF682Zm1ly13Ix9MXAJ8NaIeCoVLweOT8vHA7cA9wIHSJooaXeKsfiVwK38\nYYz/WOD25oVvZmbDqWXo5iRgT+AGSQNl7wauknQG8ChwTURskzQXWAb0AxdExHpJ1wNHSroL2AKc\n1uRzMDOzIdRyM3YeMK/CpiMr7LsIWDSobAcwu94AzcysMf5krJlZ5pzozcwy50RvZpY5J3ozs8w5\n0ZuZZc6J3swsc554JAOeGMTMhuIevZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZc6J3swsc070ZmaZ\nc6I3M8ucE72ZWeZq+mSspP2Bm4DLIuIKSd8ESmnzJOD7wD8BPwFWp/K+iDgxTUX4deDFwEbg5LIp\nCc3MrMWGTfSSxgOXAysGyiLixLLt84Gr/rApZg6q4mzgjoi4RNL7gI+lHzMza4Nahm62AMcAawZv\nUDGJ7MSIuG+I4w8HFqflpcARIw3SzMzqV8ucsduB7WUTg5f7EEVvf8BkSYuAlwFXRsTXgMlAX9q+\nFpgyXJu9veMYO3bMcLt1RKk0odMhNKzV59CK+rv5ujv29uvWuKE1sdf97ZWSdgUOiYgzU9FvgU8B\n11GMx98nafDXKvbUUve6dZvqDaulSqUJ9PVt6HQYDWv1OTS7/m6+7o69/bo1bmg89movEo18TfGh\nwLNDNhGxAViQVp+U9ANgP4ohn8nAemAqFYaAzMysdRp5vPIA4McDK5LeKOmf0/J44H8ADwC3AgM3\nb48HbmmgTTMzG6FanrqZDlwKTAO2SToBeAfFWPvDZbuuBN4t6R5gDHBRRDwm6f8A10laCTwNnNLc\nUzAzs6HUcjN2NTCzwqazBu23HTitwvEbgb+tLzwzM2uUPxlrZpY5J3ozs8w50ZuZZc6J3swsc070\nZmaZc6I3M8ucE72ZWeac6M3MMudEb2aWOSd6M7PMOdGbmWXOid7MLHNO9GZmmXOiNzPLnBO9mVnm\nnOjNzDJX05yxkvYHbgIui4grJC0EplNMCA5wSUTcLGkWcDawE5gXEVdL2gVYCLwC2AHMjohHmnsa\nZmZWTS1TCY4HLgdWDNp0bkT8+6D9zgPeAGwFVklaDBwLPB0RsyS9CbgIOKlJ8ZuZ2TBqGbrZAhwD\nrBlmvwOBVRGxPiI2A3cDBwOHA4vTPstTmZmZtUktc8ZuB7ZLGrzpg5LOAdYCHwQmA31l29dSTCD+\nbHlE7JTUL2nXiNharc3e3nGMHTtmRCfSLqXShE6H0LBWn0Mr6u/m6+7Y269b44bWxF7TGH0F1wK/\njYgfSZoLfBr43qB9eqocW638WevWbaozrNYqlSbQ17eh02E0rNXn0Oz6u/m6O/b269a4ofHYq71I\n1PXUTUSsiIgfpdUlwGsphnYml+02NZU9W55uzPYM1Zs3M7PmqivRS7pR0t5pdSZwP3AvcICkiZJ2\npxiLXwncCpyY9j0WuL2hiM3MbERqeepmOnApMA3YJukEiqdwrpe0CdhI8cjk5jSMswzoBy6IiPWS\nrgeOlHQXxY3d01pyJmZmVlEtN2NXU/TaB7uxwr6LgEWDynYAs+uMz8zMGlTvzVizpplz8W0jPmb+\n3MNaEIlZnvwVCGZmmXOiNzPLnBO9mVnmnOjNzDLnRG9mljknejOzzDnRm5llzonezCxzTvRmZplz\nojczy5wTvZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZa6m76OXtD9wE3BZRFwhaS9gAbALsA04JSJ+\nI2kbcHfZoYdTvJgsBF4B7KCYjeqR5p2CmZkNZdgevaTxFFMHrigr/iwwLyIOBRYD56Ty9RExs+xn\nB3Ay8HREHAJ8DrioqWdgZmZDqmXoZgtwDLCmrOxM/jCVYB+wxxDHH07xYgCwnGLScDMza5Na5ozd\nDmyXVF72DICkMcAHgAvTpt0kfZ1imObGiPhnYDLFiwERsVNSv6RdI2JrtTZ7e8cxduyYOk+ptUql\nCZ0OoWGtPod2XKNu+j10U6yDdWvs3Ro3tCb2uueMTUn+WuC2iBgY1vkIcB3QD9wp6c4Kh/YMV/e6\ndZvqDaulSqUJ9PVt6HQYDWv1ObTjGnXL76Gb/2a6NfZujRsaj73ai0Qjk4MvAB6MiAsGCiLiywPL\nklYAr6UY8pkM/FjSLkDPUL15MzNrrroSvaRZwNaIOL+sTMD5wCxgDMVY/CKKMf4TgWXAscDtDcZs\nZmYjMGyilzQduBSYBmyTdALwEuD3ku5Iu/00Is6U9CvgPmAnsCQi7pO0GjhS0l0USf+0pp+FmZlV\nVcvN2NXAzFoqi4iPVSjbAcwecWRmZtYU/mSsmVnmnOjNzDLnRG9mljknejOzzDnRm5llzonezCxz\nTvRmZplzojczy5wTvZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZc6J3swsc070ZmaZc6I3M8ucE72Z\nWeZqmjNW0v7ATcBlEXGFpL2Aaynmhn0cODUitqS5ZM+mmEpwXkRcnSYEXwi8AtgBzI6IR5p/KmZm\nVsmwPXpJ44HLgRVlxRcCV0bEDOAhYE7a7zzgCIqpBz8saRJwMvB0RBwCfA64qKlnYGZmQ6pl6GYL\ncAywpqxsJrAkLS+lSO4HAqsiYn1EbAbuBg4GDgcWp32XpzIzM2uTWiYH3w5sl1RePD4itqTltcAU\nYDLQV7bPc8ojYqekfkm7RsTWam329o5j7NgxIzqRdimVJnQ6hIa1+hzacY266ffQTbEO1q2xd2vc\n0JrYaxqjH0ZPk8qftW7dpvqjaaFSaQJ9fRs6HUbDWn0O7bhG3fJ76Oa/mW6NvVvjhsZjr/YiUe9T\nNxslvTAtT6UY1llD0XunWnm6MdszVG/ezMyaq95Evxw4Pi0fD9wC3AscIGmipN0pxuJXArcCJ6Z9\njwVurz9cMzMbqWGHbiRNBy4FpgHbJJ0AzAIWSjoDeBS4JiK2SZoLLAP6gQsiYr2k64EjJd1FcWP3\ntJaciZmZVVTLzdjVFE/ZDHZkhX0XAYsGle0AZtcZn5mZNcifjDUzy1wznrqxIcy5+LYRHzN/7mEt\niMTMnq/cozczy5wTvZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZc6J3swsc36O3p4XRvp5Bn+WwXLi\nHr2ZWeac6M3MMudEb2aWOSd6M7PMOdGbmWXOid7MLHN1PV4p6XTg1LKi1wM/AMYDz6Syf4iI1ZL+\nkWIqwYFZp77TQLxmZjZCdSX6iLgauBpA0qHAO4HXALMj4v6B/SS9EvhfwEHAi4GVkpalWafMzKwN\nmjF0cx7wmSrb3gj8R0RsjYg+ivllX92ENs3MrEYNfTJW0gHAryLiN5IALpS0J/Az4GxgMtBXdsha\nYArwk6Hq7e0dx9ixYxoJrWVKpQld30a319+ONppZfzuuR6t0a+zdGje0JvZGvwLhPcDCtPxF4L8i\n4mFJXwI+UGH/nloqXbduU4NhtUapNIG+vg0tb6fVbXR7/e1oo1n1t+tvphW6NfZujRsaj73ai0Sj\niX4mcBZARCwuK18KnATcDqisfCqwpsE2zcxsBOoeo5f0MmBjRGyV1CNpuaSJafNM4H7gNuAtknZN\n+08Fftpo0GZmVrtGbsZOoRhzJyL6gXnACkl3AnsBV0bEL4GvAHcCNwLvj4idjYVsZmYjUffQTUSs\nBo4uW78BuKHCfpcDl9fbjpmZNcafjDUzy5wTvZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZc6J3sws\nc070ZmaZc6I3M8ucE72ZWeac6M3MMudEb2aWOSd6M7PMOdGbmWXOid7MLHNO9GZmmatr4hFJM4Fv\nAv+din4CfAG4FhgDPA6cGhFbJM0CzgZ2AvMi4upGgzYzs9o10qP/bkTMTD9nARdSTB84A3gImCNp\nPHAecATFPLIfljSp0aDNzKx2zRy6mQksSctLKZL7gcCqiFgfEZuBu4GDm9immZkNo+45Y4FXS1oC\nTAIuAMZHxJa0bS3F5OGTgb6yYwbKh9TbO46xY8c0EFrrlEoTur6Nbq+/HW00s/52XI9W6dbYuzVu\naE3s9Sb6BymS+w3A3sDtg+rqqXJctfI/sm7dpjrDaq1SaQJ9fRta3k6r2+j2+tvRRrPqb9ffTCt0\na+zdGjc0Hnu1F4m6En1EPAZcn1YflvQb4ABJL0xDNFOBNelnctmhU4Hv19OmmZnVp64xekmzJH0k\nLU8GXgosAI5PuxwP3ALcS/ECMFHS7hTj8ysbjtrMzGpW79DNEuDrko4DdgXeD/wn8FVJZwCPAtdE\nxDZJc4FlQD9wQUSsb0LcZmZWo3qHbjYAx1bYdGSFfRcBi+ppx8zMGudPxpqZZc6J3swsc070ZmaZ\nc6I3M8ucE72ZWeac6M3MMudEb2aWOSd6M7PMOdGbmWWuka8pNrNkzsW3jWj/+XMPa1EkZs/lHr2Z\nWeac6M3MMudEb2aWOSd6M7PMOdGbmWXOid7MLHN1P14p6QvAjFTHRcDbgOnAb9Mul0TEzZJmAWcD\nO4F5EXF1YyGbmdlI1JXoJb0R2D8iDpK0B8U0grcB50bEv5ftNx44D3gDsBVYJWlxRDzVeOjN4eef\nzSx39Q7d3AmcmJafBsYDYyrsdyCwKiLWR8Rm4G6KCcLNzKxN6p0zdgfwTFo9HfgOsAP4oKRzgLXA\nB4HJQF/ZoWuBKXVHa2ZmI9bQVyBIOo4i0b8JeD3w24j4kaS5wKeB7w06pKeWent7xzF2bKU3CJ1X\nKk3o+ja6vf52tNHt9TdLt8Q5WLfGDa2JvZGbsUcBnwDeHBHrgRVlm5cAXwIWUfTqB0wFvj9c3evW\nbao3rJbr69vQ9W10e/3taKPb62+GUmlCV8Q5WLfGDY3HXu1Foq4xekkvBi4B3jpwY1XSjZL2TrvM\nBO4H7gUOkDRR0u4U4/Mr62nTzMzqU2+P/iRgT+AGSQNlC4DrJW0CNgKzI2JzGsZZBvQDF6Tev5mZ\ntUm9N2PnAfMqbLqmwr6LKIZwzMysA/zJWDOzzDnRm5llzonezCxzTvRmZplzojczy5wTvZlZ5pzo\nzcwy50RvZpa5hr7UzMzax3MnWL3cozczy5wTvZlZ5pzozcwy50RvZpY5J3ozs8w50ZuZZc6J3sws\nc070ZmaZa8sHpiRdBvwVxXSCH4qIVe1o18xq5w9k5avliV7SocCfRcRBkv4cmA8c1Kr2RvrHamaW\nu3b06A8Hvg0QET+T1CvpRRHxuza0bWajRDveMfhdSWU9/f39LW1A0jzg5oi4Ka2vBE6PiAda2rCZ\nmQGduRnb04E2zcyet9qR6NcAk8vWXwY83oZ2zcyM9iT6W4ETACT9T2BNRGxoQ7tmZkYbxugBJF0M\n/A2wE/hARPy45Y2amRnQpkRvZmad40/GmpllzonezCxznjN2BCS9ELgf+ExELOxwODWTNAv4KLAd\nOC8ibu5wSDWRtDvwVaAX+BPggohY1tmohiZpf+Am4LKIuELSXsC1wBiKp81OjYgtnYyxmiqxLwB2\nAbYBp0TEbzoZYzWDYy8rPwq4JSJG5WPdFa75LsA1wL7ABuCEiFjXaDvu0Y/MJ4GnOh3ESEjaAzgf\nOAR4K3BcZyMakdOAiIg3Ujy59cXOhjM0SeOBy4EVZcUXAldGxAzgIWBOJ2IbTpXYPwvMi4hDgcXA\nOZ2IbThVYkfSbsC5jNLHuavE/V6gLyLeAFwPzGhGW070NZK0H/BqoCt6w2WOAJZHxIaIeDwi3tfp\ngEbgSWCPtNyb1kezLcAxFJ8dGTATWJKWl1L8PkajSrGfCdyYlvv4w+9itKkUO8DHgSuBrW2PqDaV\n4j4W+BpARMyLiCWVDhwpJ/raXcoo7dEMYxowTtISSSslHd7pgGoVEd8AXi7pIeBO4CMdDmlIEbE9\nIjYPKh5fNlSzFpjS5rBqUin2iHgmInZIGgN8APh6Z6IbWqXYJb0KeF1EfLNDYQ2ryt/LNOBoSXdI\n+oakSc1oy4m+BpLeBdwTEf+v07HUoYeiJ/YOiqGQBZJG5XjlYJJOAX4ZEfsChwFXDHPIaNcV171c\nSvLXArdFxIrh9h9FLqM7O2Y9FMOVMynuB57bjEqd6GvzFuA4Sd8H3gN8StJofQs+2BPA91Lv4WGK\nGzylDsdUq4OBZQDpQ3YvS4mnm2xMN/EBpvLc4YXRbgHwYERc0OlAaiVpKrAf8LX0f3aKpO92OKxa\nPQEMxLoMeE0zKvVTNzWIiJMGliV9GvhFRCzvXEQjciuwUNLnKca5d2f0j3UPeAg4ELhR0iuAjRGx\no8MxjdRy4HjguvTvLZ0Np3bpaa2tEXF+p2MZiYh4DNhnYF3SL9IN5W7wH8CbKV5gpwPRjEr9ydgR\nKkv0CzscSs0knQGcnlY/26wbPK2WHq+cD7yUolPyqYgYtTPLSJpOcS9nGsXjiI8Bs4CFwG7Ao8Ds\niNjWoRCrqhL7S4DfAwNzR/w0Is7sSIBDqBL7OyLiqbT9FxExrWMBVlEl7pMpni6bAmwE3h0RTzTa\nlhO9mVnmPEZvZpY5J3ozs8w50ZuZZc6J3swsc070ZmaZc6I3M8ucE72ZWeb+P0AX9gqfUNDyAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f18d1b10780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OwxsFFosfuv6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "YAXZ5a9Ufuv8",
        "colab_type": "code",
        "outputId": "44433fd7-13d1-4def-e01c-d0d3f1038a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tokens = list(set(''.join(names)))### all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2wDlZa_WfuwC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "IA2xNRH1fuwD",
        "colab_type": "code",
        "outputId": "0440740a-cc75-4ffb-b3c6-ffb8e52ed975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "token_to_id ={key:value for value,key in enumerate(tokens)}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(n_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be its position in tokens list\"\n",
        "\n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems alright!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DuCzc5jt3534",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names,max_len=None,pad=0,dtype='int32'):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len,names))\n",
        "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get,names[i]))\n",
        "        names_ix[i,:len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "_l1p3dvUfuwL",
        "colab_type": "code",
        "outputId": "15802b21-3c0b-45fe-ea93-e3f321915b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[18  9 38 47  5 47 17  6  0]\n",
            " [18 28  6  0 24 43  0  0  0]\n",
            " [18 52 24 42 15 15 42 17  0]\n",
            " [18 28 42  0 45 47 48 48 17]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7kpky8lfuwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "BU-OElnjfuwY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "Zl-H2A8rfuwc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units,activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens,activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K5weehMBfuwg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "DQQF7yO7fuwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb,h_t])\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R5FmIlwGfuwm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "1PAU914Nfuwn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09air7NSfuwq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "--ENLb1Nfuws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVZdqPwHfuwv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "KoTnh4M6fuww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix*tf.log(predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "piGkBIKIfuwz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "jUKyBJIhfuw0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8015f053-d537-471a-9746-aa58c2611db6"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "s = keras.backend.get_session()\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f18c6a2a6a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sZQOCfekfuw4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "ohjPwoGBfuw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "GjNjZz3kfuw9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "UHc_AgUTfuxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "52161eee-5531-4aac-f929-ff5eb8bfdb4c"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Perluedoooooooo\n",
            " Avyoaoooooooooo\n",
            " Fukaooooooooooo\n",
            " Elhhsneoooooooo\n",
            " Dovenaooooooooo\n",
            " Rotisoooooooooo\n",
            " Wemieamoooooooo\n",
            " Mevielaoooooooo\n",
            " Aldsriooooooooo\n",
            " xokyooooooooooo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "gVVFdCzBfuxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "13838745-5b47-47c8-cfc0-58b6b74356b0"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpelaooooooo\n",
            " Trumpaninaooooo\n",
            " Trumpeunooooooo\n",
            " Trumprioooooooo\n",
            " Trumpalaooooooo\n",
            " Trumpneoooooooo\n",
            " Trumpoooooooooo\n",
            " Trumpenneoooooo\n",
            " Trumpintooooooo\n",
            " Trumptaoooooooo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mc2-kjs1fuxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "QzY3kIJTfuxL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"1atxrini1FTMZNHJ\"\n",
        "COURSERA_EMAIL = \"claudio.gaiaschi@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "Svlk3ZDSfuxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3752761a-6f48-4b1d-a907-ed274e350487"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F73_BEvSfuxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "7SuQrR10fuxT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "gBGee4NYfuxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZ4eR6NFfuxa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "Swn0_prZfuxb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "ffTsIVD7fuxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}